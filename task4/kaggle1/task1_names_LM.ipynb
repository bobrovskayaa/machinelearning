{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/natasha/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  if __name__ == '__main__':\n",
      "/home/natasha/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('linear_train.txt', sep=', ', names=['word', 'y'])\n",
    "#train = data.sample(frac=0.9)\n",
    "#test = data.sample(frac=0.1)\n",
    "resultative = pd.read_csv('linear_test.txt', sep=', ', names=['word'])\n",
    "example = pd.read_csv('linear_ans_example.txt', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1 = open('tests_LM_2.txt', 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 7 0.854191222024\n",
      "1 8 0.853925541439\n",
      "1 9 0.853538548432\n",
      "1 10 0.853226342724\n",
      "2 7 0.852922191461\n",
      "2 8 0.852729742588\n",
      "2 9 0.852402741737\n",
      "2 10 0.852195092409\n",
      "0.854191222024\n"
     ]
    }
   ],
   "source": [
    "my_est = 0.5\n",
    "for i in range(1,3):\n",
    "    for j in range(7,11):\n",
    "        pipeline = Pipeline([(\"vectorizer\", CountVectorizer(ngram_range=(i, j), analyzer='char_wb', binary=True)), (\"algo\", LogisticRegression())])\n",
    "        pipeline.fit(train.word, train.y)\n",
    "        preds = pipeline.predict(test.word)\n",
    "        arr = cross_val_score(pipeline, test.word, test.y, cv=5, scoring='roc_auc')\n",
    "        if (np.mean(arr) > my_est):\n",
    "            my_est = np.mean(arr)\n",
    "        print i, j, np.mean(arr)\n",
    "        f1.write(str(i) + ' ' + str(j) + ' ' + str(np.mean(arr)) + '\\n')\n",
    "print my_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npreds = pipeline.predict(resultative.word)\\nresult = pd.DataFrame({\"Answer\":preds, \"Id\":example.index})\\nresult.set_index(\\'Id\\', inplace=True)\\nresult.to_csv(\\'result.csv\\')'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "preds = pipeline.predict(resultative.word)\n",
    "result = pd.DataFrame({\"Answer\":preds, \"Id\":example.index})\n",
    "result.set_index('Id', inplace=True)\n",
    "result.to_csv('result.csv')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer', CountVectorizer(analyzer='char_wb', binary=True, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 8), preprocessor=None, stop_words=None...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = make_pipeline(CountVectorizer(analyzer='char_wb', ngram_range=(1, 8), lowercase = True, binary = True), LogisticRegression(C=3))\n",
    "pipeline.fit(train.word, train.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = pipeline.predict_proba(resultative.word)[:,1]\n",
    "result = pd.DataFrame({\"Answer\":preds, \"Id\":example.index})\n",
    "result.set_index('Id', inplace=True)\n",
    "result.to_csv('result5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
