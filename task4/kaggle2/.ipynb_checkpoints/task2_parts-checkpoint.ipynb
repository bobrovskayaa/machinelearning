{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтение данных из файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f2 = open('task2_lemmas_train_single', 'w')\n",
    "with open('task2_lemmas_train') as f:\n",
    "    for line in f:\n",
    "        f2.write(str(line.split(',')[0]) + ',' + str(line.split(',')[1]) + ',' + str(line.split(',')[2]) + '\\n')\n",
    "f.close()\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('task2_lemmas_train_single', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = data[:len(data)/10*9]\n",
    "test = data[len(data)/10*9:]\n",
    "resultative = pd.read_csv('task2_lemmas_test', sep=',')\n",
    "example = pd.read_csv('task2_lemmas_test', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#найти наибольшую общую последовательность\n",
    "def lcs(a, b):\n",
    "    a, b = (a, b) if len(a) < len(b) else (b, a)\n",
    "    pos = 0\n",
    "    substr = \"\"\n",
    "    search_str = a[:]\n",
    "    while ( pos != len(a) ):\n",
    "        while ( len(search_str) > len(substr) ):\n",
    "            if search_str in b:\n",
    "                substr = search_str[:]\n",
    "                break\n",
    "            else:\n",
    "                search_str = search_str[:-1]\n",
    "        pos += 1\n",
    "        search_str = a[pos:]\n",
    "    return substr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vergogn'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcs('vergognerete', 'vergognare+V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vergognerete'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iat[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#функция добавляет новые столбцы в DataFrame для удобной работы\n",
    "def decomposition(train):\n",
    "    train['y2'] = [train.iat[i,2][:-2] for i in range(len(train))]\n",
    "    train['root'] = [lcs(train.iat[i,1],train.iat[i,2]) for i in range(len(train))]\n",
    "    train['part'] = [train.iat[i,2][-1] for i in range(len(train))]\n",
    "    train['len_suf_x'] = [len(train.iat[i,1]) - len(train.iat[i,4]) for i in range(len(train))]\n",
    "    train['len_suf_у'] = [len(train.iat[i,3]) - len(train.iat[i,4]) for i in range(len(train))]\n",
    "    suf_y = []\n",
    "    for i in range(len(train)):\n",
    "        if (int(train.iat[i,7]) == 0):\n",
    "            suf_y.append('')\n",
    "        else:\n",
    "            suf_y.append(train.iat[i,3][-int(train.iat[i,7]):])\n",
    "    train['suf_y'] = suf_y\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/natasha/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/natasha/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/home/natasha/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/natasha/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/natasha/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/natasha/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "train = decomposition(train)\n",
    "#test = decomposition(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "      <th>y2</th>\n",
       "      <th>root</th>\n",
       "      <th>part</th>\n",
       "      <th>len_suf_x</th>\n",
       "      <th>len_suf_у</th>\n",
       "      <th>suf_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>vergognerete</td>\n",
       "      <td>vergognare+V</td>\n",
       "      <td>vergognare</td>\n",
       "      <td>vergogn</td>\n",
       "      <td>V</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>amnistiavate</td>\n",
       "      <td>amnistiare+V</td>\n",
       "      <td>amnistiare</td>\n",
       "      <td>amnistia</td>\n",
       "      <td>V</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>re</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>menomazione</td>\n",
       "      <td>menomazione+N</td>\n",
       "      <td>menomazione</td>\n",
       "      <td>menomazione</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>sfaldavamo</td>\n",
       "      <td>sfaldare+V</td>\n",
       "      <td>sfaldare</td>\n",
       "      <td>sfalda</td>\n",
       "      <td>V</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>re</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>sfodererei</td>\n",
       "      <td>sfoderare+V</td>\n",
       "      <td>sfoderare</td>\n",
       "      <td>sfoder</td>\n",
       "      <td>V</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>are</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id             X              y           y2         root part  len_suf_x  \\\n",
       "0   1  vergognerete   vergognare+V   vergognare      vergogn    V          5   \n",
       "1   2  amnistiavate   amnistiare+V   amnistiare     amnistia    V          4   \n",
       "2   3   menomazione  menomazione+N  menomazione  menomazione    N          0   \n",
       "3   4    sfaldavamo     sfaldare+V     sfaldare       sfalda    V          4   \n",
       "4   5    sfodererei    sfoderare+V    sfoderare       sfoder    V          4   \n",
       "\n",
       "   len_suf_у suf_y  \n",
       "0          3   are  \n",
       "1          2    re  \n",
       "2          0        \n",
       "3          2    re  \n",
       "4          3   are  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/natasha/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/natasha/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/home/natasha/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/natasha/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/natasha/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/natasha/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "test = decomposition(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пробуем pipeline и cross_val на train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20244251197\n"
     ]
    }
   ],
   "source": [
    "#1. сколько букв надо отрезать\n",
    "pipeline = make_pipeline(CountVectorizer(ngram_range=(1, 6), lowercase=True), LogisticRegression())\n",
    "arr = cross_val_score(pipeline, train.X, train.len_suf_x, cv=5, scoring='accuracy')\n",
    "print np.mean(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/natasha/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.417716306202\n"
     ]
    }
   ],
   "source": [
    "#2. какой суффикс у начальной формы\n",
    "arr = cross_val_score(pipeline, train.X, train.suf_y, cv=5, scoring='accuracy')\n",
    "print np.mean(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.810818909946\n"
     ]
    }
   ],
   "source": [
    "#3. какая часть речи\n",
    "arr = cross_val_score(pipeline, train.X, train.part, cv=5, scoring='accuracy')\n",
    "print np.mean(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пробуем pipeline на train и accuracy на test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.205074173972\n"
     ]
    }
   ],
   "source": [
    "#1. сколько букв надо отрезать\n",
    "pipeline1 = make_pipeline(CountVectorizer(ngram_range=(1, 8), lowercase=True), LogisticRegression())\n",
    "pipeline1.fit(train.X, train.len_suf_x)\n",
    "preds1 = pipeline1.predict(test.X)\n",
    "print accuracy_score(test.len_suf_x, preds1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.414615643965\n"
     ]
    }
   ],
   "source": [
    "#2. какой суффикс у начальной формы\n",
    "pipeline2 = make_pipeline(CountVectorizer(ngram_range=(1, 8), lowercase=True), LogisticRegression())\n",
    "pipeline2.fit(train.X, train.suf_y)\n",
    "preds2 = pipeline2.predict(test.X)\n",
    "print accuracy_score(test.suf_y, preds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    5\n",
      "1    4\n",
      "2    0\n",
      "3    4\n",
      "4    4\n",
      "Name: len_suf_x, dtype: int64\n",
      "[2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print train.len_suf_x[0:5]\n",
    "print preds1[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.807821982468\n"
     ]
    }
   ],
   "source": [
    "#3. какая часть речи\n",
    "pipeline3 = make_pipeline(CountVectorizer(ngram_range=(1, 8), lowercase=True), LogisticRegression())\n",
    "pipeline3.fit(train.X, train.part)\n",
    "preds3 = pipeline3.predict(test.X)\n",
    "print accuracy_score(test.part, preds3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.140846257586\n"
     ]
    }
   ],
   "source": [
    "preds = [(str(test.iat[i,1][:-int(preds1[i])]) + str(preds2[i]) + '+' +str(preds3[i])) for i in range(len(test))]\n",
    "print accuracy_score(test.y, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пробуем CountVectorizer(fit_transform) и accuracy на train (train делится на 4/5 для обучения и 1/5 для предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.919794820395\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(analyzer='char_wb', ngram_range=(1, 7), lowercase = True)\n",
    "X = cv.fit_transform(train.X)\n",
    "print np.mean(cross_val_score(LogisticRegression(), X, train.len_suf_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(analyzer='char_wb', ngram_range=(1, 8), lowercase = True)\n",
    "X = cv.fit_transform(train.X)\n",
    "ind = 4*X.shape[0]/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len predicted\n",
      "ending predicted\n",
      "class predicted\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X[:ind], train.len_suf_x[:ind])\n",
    "len_pred = clf.predict(X[ind:])\n",
    "print 'len predicted'\n",
    "clf.fit(X[:ind], train.suf_y[:ind])\n",
    "ending_pred = clf.predict(X[ind:])\n",
    "print 'ending predicted'\n",
    "clf.fit(X[:ind], train.part[:ind])\n",
    "class_pred = clf.predict(X[ind:])\n",
    "print 'class predicted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21356 21356 21356 85420\n"
     ]
    }
   ],
   "source": [
    "print len(len_pred), len(ending_pred), len(class_pred), ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sbracciare+V'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.X[ind][:-len_pred[0]] + ending_pred[0]  + '+' + class_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = [(train.X[ind+i][:-len_pred[i]] + ending_pred[i] + '+' + class_pred[i]) for i in range(len(len_pred))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81461884247986516"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(train.y[ind:], predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предскажем результат для resultative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_data = data.drop(['y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_data = pd.concat([new_data,resultative])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29661\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(analyzer='char_wb', ngram_range=(1, 8), lowercase = True)\n",
    "X = cv.fit_transform(all_data.X)\n",
    "IND = len(resultative)\n",
    "print IND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148301 148301\n"
     ]
    }
   ],
   "source": [
    "print len(all_data), len(data) + len(resultative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = decomposition(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind = len(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len predicted\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X[:ind], train.len_suf_x)\n",
    "len_pred = clf.predict(X[ind:])\n",
    "print 'len predicted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ending predicted\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X[:ind], train.suf_y)\n",
    "ending_pred = clf.predict(X[ind:])\n",
    "print 'ending predicted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class predicted\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X[:ind], train.part)\n",
    "class_pred = clf.predict(X[ind:])\n",
    "print 'class predicted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = [(resultative.X[i][:-len_pred[i]] + ending_pred[i] + '+' + class_pred[i]) for i in range(len(len_pred))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gettonare+V', 'incidentale+A', 'involtare+V', 'lievo+N', 'comunistizzare+V', 'vidimare+V', 'imbrodre+V', 'e+V', 'cifrare+V', 'compassare+V']\n"
     ]
    }
   ],
   "source": [
    "print predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\"Category\":predictions, \"Id\":example.index})\n",
    "result.set_index('Id', inplace=True)\n",
    "result.to_csv('result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29661 29661\n"
     ]
    }
   ],
   "source": [
    "print len(predictions), len(resultative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Некоторые слова обрезаются полностью - неправильное вычисление predictions\n",
    "\n",
    "Исправление:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148301 148301\n"
     ]
    }
   ],
   "source": [
    "new_data = data.drop(['y'], axis=1)\n",
    "all_data = pd.concat([new_data,resultative])\n",
    "cv = CountVectorizer(analyzer='char_wb', ngram_range=(1, 8), lowercase = True)\n",
    "X = cv.fit_transform(all_data.X)\n",
    "print len(all_data), len(data) + len(resultative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = decomposition(data)\n",
    "ind = len(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X[:ind], train.len_suf_x)\n",
    "len_pred = clf.predict(X[ind:])\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X[:ind], train.suf_y)\n",
    "ending_pred = clf.predict(X[ind:])\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X[:ind], train.part)\n",
    "class_pred = clf.predict(X[ind:])\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beggining = []\n",
    "for i in range(len(len_pred)):\n",
    "    if (len_pred[i] == 0):\n",
    "        beggining.append(resultative.X[i])\n",
    "    else :\n",
    "        beggining.append(resultative.X[i][:-len_pred[i]])\n",
    "\n",
    "predictions = [(beggining[i] + ending_pred[i] + '+' + class_pred[i]) for i in range(len(len_pred))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gettonare+V', 'incidentale+A', 'involtare+V', 'lievo+N', 'comunistizzare+V', 'vidimare+V', 'imbrodre+V', 'strillare+V', 'cifrare+V', 'compassare+V']\n"
     ]
    }
   ],
   "source": [
    "print predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29661 29661\n"
     ]
    }
   ],
   "source": [
    "print len(predictions), len(resultative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это лучшие полученные результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result2 = pd.DataFrame({\"Category\":predictions, \"Id\":example.index})\n",
    "result2.set_index('Id', inplace=True)\n",
    "result2.to_csv('result2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Попробуем другие параметры\n",
    "\n",
    "1 6 ~ хуже, чем 1 8\n",
    "\n",
    "1 9 ~ 1 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv done\n",
      "148301 148301\n",
      "done\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-3b727ac36cea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mlen_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'done'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuf_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mending_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'done'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/natasha/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/logistic.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m                 sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/natasha/anaconda2/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m         epsilon, sample_weight)\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m     \u001b[0;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msklearn/svm/liblinear.pyx\u001b[0m in \u001b[0;36msklearn.svm.liblinear.train_wrap (sklearn/svm/liblinear.c:2381)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "new_data = data.drop(['y'], axis=1)\n",
    "all_data = pd.concat([new_data,resultative])\n",
    "cv = CountVectorizer(analyzer='char_wb', ngram_range=(1, 9), lowercase = True)\n",
    "X = cv.fit_transform(all_data.X)\n",
    "print 'cv done'\n",
    "print len(all_data), len(data) + len(resultative)\n",
    "\n",
    "train = decomposition(data)\n",
    "ind = len(new_data)\n",
    "clf = LogisticRegression(C=8)\n",
    "\n",
    "clf.fit(X[:ind], train.len_suf_x)\n",
    "len_pred = clf.predict(X[ind:])\n",
    "print 'done'\n",
    "clf.fit(X[:ind], train.suf_y)\n",
    "ending_pred = clf.predict(X[ind:])\n",
    "print 'done'\n",
    "clf.fit(X[:ind], train.part)\n",
    "class_pred = clf.predict(X[ind:])\n",
    "print 'done'\n",
    "\n",
    "beggining = []\n",
    "for i in range(len(len_pred)):\n",
    "    if (len_pred[i] == 0):\n",
    "        beggining.append(resultative.X[i])\n",
    "    else :\n",
    "        beggining.append(resultative.X[i][:-len_pred[i]])\n",
    "\n",
    "predictions = [(beggining[i] + ending_pred[i] + '+' + class_pred[i]) for i in range(len(len_pred))]\n",
    "\n",
    "print predictions[:10]\n",
    "print len(predictions), len(resultative)\n",
    "\n",
    "result3 = pd.DataFrame({\"Category\":predictions, \"Id\":example.index})\n",
    "result3.set_index('Id', inplace=True)\n",
    "result3.to_csv('result4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
